name: CI

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  build_base_image:
    runs-on: ubuntu-20.04
    strategy:
      fail-fast: false
    steps:
      - uses: actions/checkout@v2
        with:
          fetch-depth: 0

      - name: Prepare
        id: prep
        run: |
          TAG=$(echo $GITHUB_SHA | head -c7)
          echo ::set-output name=tag::${TAG}
          VERSION=$(cat base-image/VERSION | tr -d '\n')
          echo ::set-output name=version::${VERSION}

      - name: Login to GitHub package docker registry
        run: |
          echo "${{ secrets.GITHUB_TOKEN }}" | \
            docker login --username ${{ github.actor }} --password-stdin ghcr.io

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v1
        with:
          driver-opts: |
            network=host

      - name: Build base-image Docker Image
        uses: docker/build-push-action@v2
        with:
          context: .
          file: base-image/Dockerfile
          load: true
          tags: ghcr.io/estuary/base-image:local

      - name: Push base-image image
        uses: docker/build-push-action@v2
        with:
          context: .
          file: base-image/Dockerfile
          push: true
          tags: ghcr.io/estuary/base-image:${{ steps.prep.outputs.tag }}

      - name: Push base-image image with 'dev' tag
        if: ${{ github.event_name == 'push' }}
        uses: docker/build-push-action@v2
        with:
          context: .
          file: base-image/Dockerfile
          push: true # See 'if' above
          tags: ghcr.io/estuary/base-image:dev,ghcr.io/estuary/base-image:${{ steps.prep.outputs.version }}

  build_connectors:
    runs-on: ubuntu-20.04
    needs: build_base_image
    strategy:
      fail-fast: false
      matrix:
        connector:
          - source-gcs
          - source-hello-world
          - source-http-file
          - source-test
          - source-firestore
          - source-kafka
          - source-kinesis
          - source-mysql
          - source-postgres
          - source-s3
          - materialize-bigquery
          - materialize-elasticsearch
          - materialize-firebolt
          - materialize-google-pubsub
          - materialize-google-sheets
          - materialize-postgres
          - materialize-postgres-rc
          - materialize-rockset
          - materialize-s3-parquet
          - materialize-snowflake
          - materialize-webhook

    steps:
      - uses: actions/checkout@v2
        with:
          fetch-depth: 0

      - name: Prepare
        id: prep
        run: |
          TAG=$(echo $GITHUB_SHA | head -c7)
          echo ::set-output name=tag::${TAG}
          VERSION=$(cat ${{ matrix.connector }}/VERSION | tr -d '\n')
          echo ::set-output name=version::${VERSION}

      - name: Download latest Flow release binaries and add them to $PATH
        run: |
          ./fetch-flow.sh
          echo "${PWD}/flow-bin" >> $GITHUB_PATH

      - name: Install kafkactl
        if: matrix.connector == 'source-kafka'
        env:
          version: 1.20.0
          checksum: ff285ce7eefa956234e65f9ff98160c2c365973ca598187cee81da1377b139d1
        run: |
          curl -L -o "kafkactl_${version}_linux_amd64.deb" "https://github.com/deviceinsight/kafkactl/releases/download/v${version}/kafkactl_${version}_linux_amd64.deb" && \
          echo "$checksum kafkactl_${version}_linux_amd64.deb" | sha256sum --check && \
          sudo dpkg -i "kafkactl_${version}_linux_amd64.deb" && \
          rm "kafkactl_${version}_linux_amd64.deb"

      - name: Set up Cloud SDK
        if: matrix.connector == 'source-gcs'
        uses: google-github-actions/setup-gcloud@v0
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}
          service_account_key: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}
          export_default_credentials: true

      - name: Configure AWS credentials from Test account
        if: matrix.connector == 'source-kinesis' || matrix.connector == 'source-s3'
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-2

      - name: Login to GitHub package docker registry
        run: |
          echo "${{ secrets.GITHUB_TOKEN }}" | \
            docker login --username ${{ github.actor }} --password-stdin ghcr.io

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v1
        with:
          driver-opts: |
            network=host

      - name: Create docker network flow-test
        run: docker network create flow-test

      - name: Start Dockerized test infrastructure
        if: matrix.connector == 'source-postgres' || matrix.connector == 'source-mysql'
        run: |
          docker-compose --file ${{ matrix.connector }}/docker-compose.yaml up --detach

      - name: Build ${{ matrix.connector }} Docker Image
        uses: docker/build-push-action@v2
        with:
          context: .
          file: ${{ matrix.connector }}/Dockerfile
          load: true
          build-args: BASE_IMAGE=ghcr.io/estuary/base-image:${{ steps.prep.outputs.tag }}
          tags: ghcr.io/estuary/${{ matrix.connector }}:local
          secrets: |
            "rockset_api_key=${{ secrets.ROCKSET_API_KEY }}"

      - name: Start Dockerized test infrastructure
        if: matrix.connector == 'source-kafka'
        run: |
          docker-compose --file infra/docker-compose.yaml up --detach zookeeper
          docker-compose --file infra/docker-compose.yaml up --detach kafka

      - name: Source connector ${{ matrix.connector }} integration tests
        if: |
          contains(fromJson('[
            "source-gcs",
            "source-kafka",
            "source-kinesis",
            "source-mysql",
            "source-postgres",
            "source-s3"
            ]'), matrix.connector)
        env:
          GCP_SERVICE_ACCOUNT_KEY: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          DEFAULT_AWS_REGION: ${{ secrets.DEFAULT_AWS_REGION }}
          AWS_DEFAULT_OUTPUT: json
          ROCKSET_API_KEY: ${{ secrets.ROCKSET_API_KEY }}
          MYSQL_DATABASE: test

        run: CONNECTOR=${{ matrix.connector }} VERSION=local ./tests/run.sh;

      - name: Materialization connector ${{ matrix.connector }} integration tests
        if: |
          contains(fromJson('[
              "materialize-elasticsearch",
              "materialize-google-sheets",
              "materialize-postgres-rc",
              "materialize-s3-parquet"
            ]'), matrix.connector)
        env:
          GCP_SERVICE_ACCOUNT_KEY: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}

        run: CONNECTOR=${{ matrix.connector }} VERSION=local tests/materialize/run.sh;

      - name: Push ${{ matrix.connector }} image
        uses: docker/build-push-action@v2
        with:
          context: .
          build-args: BASE_IMAGE=ghcr.io/estuary/base-image:${{ steps.prep.outputs.tag }}
          file: ${{ matrix.connector }}/Dockerfile
          push: true
          tags: ghcr.io/estuary/${{ matrix.connector }}:${{ steps.prep.outputs.tag }}

      - name: Push ${{ matrix.connector }} image with 'dev' tag
        if: ${{ github.event_name == 'push' }}
        uses: docker/build-push-action@v2
        with:
          context: .
          file: ${{ matrix.connector }}/Dockerfile
          push: true # See 'if' above
          tags: ghcr.io/estuary/${{ matrix.connector }}:dev,ghcr.io/estuary/${{ matrix.connector }}:${{ steps.prep.outputs.version }}
