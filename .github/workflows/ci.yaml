name: CI

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  build_base_image:
    runs-on: ubuntu-20.04
    strategy:
      fail-fast: false
    steps:
      - uses: actions/checkout@v2
        with:
          fetch-depth: 0

      - name: Prepare
        id: prep
        run: |
          TAG=$(echo $GITHUB_SHA | head -c7)
          echo ::set-output name=tag::${TAG}
          VERSION=$(cat base-image/VERSION | tr -d '\n')
          echo ::set-output name=version::${VERSION}

      - name: Login to GitHub package docker registry
        run: |
          echo "${{ secrets.GITHUB_TOKEN }}" | \
            docker login --username ${{ github.actor }} --password-stdin ghcr.io

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v1
        with:
          driver-opts: |
            network=host

      - name: Build base-image Docker Image
        uses: docker/build-push-action@v2
        with:
          context: .
          file: base-image/Dockerfile
          load: true
          tags: ghcr.io/estuary/base-image:local

      - name: Push base-image image
        uses: docker/build-push-action@v2
        with:
          context: .
          file: base-image/Dockerfile
          push: true
          tags: ghcr.io/estuary/base-image:${{ steps.prep.outputs.tag }}

      - name: Push base-image image with 'dev' tag
        if: ${{ github.event_name == 'push' }}
        uses: docker/build-push-action@v2
        with:
          context: .
          file: base-image/Dockerfile
          push: true # See 'if' above
          tags: ghcr.io/estuary/base-image:dev,ghcr.io/estuary/base-image:${{ steps.prep.outputs.version }}

  build_connectors:
    runs-on: ubuntu-20.04
    needs: build_base_image
    strategy:
      fail-fast: false
      matrix:
        connector:
          - source-alpaca
          - source-gcs
          - source-hello-world
          - source-http-file
          - source-http-ingest
          - source-test
          - source-firestore
          - source-kafka
          - source-kinesis
          - source-mongodb
          - source-mysql
          - source-postgres
          - source-s3
          - source-sqlserver
          - materialize-bigquery
          - materialize-redshift
          - materialize-elasticsearch
          - materialize-firebolt
          - materialize-google-pubsub
          - materialize-google-sheets
          - materialize-mongodb
          - materialize-postgres
          - materialize-rockset
          - materialize-s3-parquet
          - materialize-sqlite
          - materialize-snowflake
          - materialize-webhook

    steps:
      - uses: actions/checkout@v2
        with:
          fetch-depth: 0

      - name: Prepare
        id: prep
        run: |
          TAG=$(echo $GITHUB_SHA | head -c7)
          echo ::set-output name=tag::${TAG}
          VERSION=$(cat ${{ matrix.connector }}/VERSION | tr -d '\n')
          echo ::set-output name=version::${VERSION}

      - name: Download latest Flow release binaries and add them to $PATH
        run: |
          # TODO(johnny): remove FLOW_RELEASE once sql branch is merged.
          FLOW_RELEASE=dev-sql ./fetch-flow.sh
          echo "${PWD}/flow-bin" >> $GITHUB_PATH

      - name: Install kafkactl
        if: matrix.connector == 'source-kafka'
        env:
          version: 1.20.0
          checksum: ff285ce7eefa956234e65f9ff98160c2c365973ca598187cee81da1377b139d1
        run: |
          curl -L -o "kafkactl_${version}_linux_amd64.deb" "https://github.com/deviceinsight/kafkactl/releases/download/v${version}/kafkactl_${version}_linux_amd64.deb" && \
          echo "$checksum kafkactl_${version}_linux_amd64.deb" | sha256sum --check && \
          sudo dpkg -i "kafkactl_${version}_linux_amd64.deb" && \
          rm "kafkactl_${version}_linux_amd64.deb"

      - name: Set up Cloud SDK
        if: matrix.connector == 'source-gcs'
        uses: google-github-actions/setup-gcloud@v0
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}
          service_account_key: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}
          export_default_credentials: true

      - name: Configure AWS credentials from Test account
        if: matrix.connector == 'source-kinesis' || matrix.connector == 'source-s3'
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-2

      - name: Login to GitHub package docker registry
        run: |
          echo "${{ secrets.GITHUB_TOKEN }}" | \
            docker login --username ${{ github.actor }} --password-stdin ghcr.io

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v1
        with:
          driver-opts: |
            network=host

      - name: Create docker network flow-test
        run: docker network create flow-test

      - name: Start Dockerized test infrastructure
        if: |
          contains(fromJson('[
            "source-mysql",
            "source-postgres",
            "source-sqlserver"
            ]'), matrix.connector)
        run: |
          docker compose --file ${{ matrix.connector }}/docker-compose.yaml up --wait
          docker logs ${{ matrix.connector }}-db-1

      - name: Build ${{ matrix.connector }} Docker Image
        uses: docker/build-push-action@v2
        with:
          context: .
          file: ${{ matrix.connector }}/Dockerfile
          load: true
          build-args: BASE_IMAGE=ghcr.io/estuary/base-image:${{ steps.prep.outputs.tag }}
          tags: ghcr.io/estuary/${{ matrix.connector }}:local
          secrets: |
            "rockset_api_key=${{ secrets.ROCKSET_API_KEY }}"

      - name: Start Dockerized test infrastructure
        if: matrix.connector == 'source-kafka'
        run: |
          docker compose --file infra/docker-compose.yaml up --detach zookeeper
          docker compose --file infra/docker-compose.yaml up --detach kafka

      - name: Source connector ${{ matrix.connector }} integration tests
        if: |
          contains(fromJson('[
            "source-gcs",
            "source-kafka",
            "source-kinesis",
            "source-mysql",
            "source-postgres",
            "source-s3",
            "source-sqlserver"
            ]'), matrix.connector)
        env:
          GCP_SERVICE_ACCOUNT_KEY: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          DEFAULT_AWS_REGION: ${{ secrets.DEFAULT_AWS_REGION }}
          AWS_DEFAULT_OUTPUT: json
          ROCKSET_API_KEY: ${{ secrets.ROCKSET_API_KEY }}
          MYSQL_DATABASE: test

        run: CONNECTOR=${{ matrix.connector }} VERSION=local ./tests/run.sh;

      - name: Materialization connector ${{ matrix.connector }} integration tests
        if: |
          contains(fromJson('[
              "materialize-elasticsearch",
              "materialize-google-sheets",
              "materialize-postgres",
              "materialize-s3-parquet",
              "materialize-mongodb"
            ]'), matrix.connector)
        env:
          GCP_SERVICE_ACCOUNT_KEY: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}

        run: CONNECTOR=${{ matrix.connector }} VERSION=local tests/materialize/run.sh;

      - name: Push ${{ matrix.connector }} image with commit SHA tag
        uses: docker/build-push-action@v2
        with:
          context: .
          build-args: BASE_IMAGE=ghcr.io/estuary/base-image:${{ steps.prep.outputs.tag }}
          file: ${{ matrix.connector }}/Dockerfile
          push: true
          tags: ghcr.io/estuary/${{ matrix.connector }}:${{ steps.prep.outputs.tag }}

      - name: Push ${{ matrix.connector }} image with 'dev' and $VERSION tag
        if: ${{ github.event_name == 'push' }}
        uses: docker/build-push-action@v2
        with:
          context: .
          file: ${{ matrix.connector }}/Dockerfile
          push: true # See 'if' above
          tags: ghcr.io/estuary/${{ matrix.connector }}:dev,ghcr.io/estuary/${{ matrix.connector }}:${{ steps.prep.outputs.version }}

      - name: Install psql
        if: ${{ github.event_name == 'push' }}
        run: |
          sudo apt update
          sudo apt install postgresql

      - name: Refresh connector tags for ${{ matrix.connector }}
        if: ${{ github.event_name == 'push' }}
        env:
          PGHOST: ${{ secrets.POSTGRES_CONNECTOR_REFRESH_HOST }}
          PGUSER: ${{ secrets.POSTGRES_CONNECTOR_REFRESH_USER }}
          PGPASSWORD: ${{ secrets.POSTGRES_CONNECTOR_REFRESH_PASSWORD }}
          PGDATABASE: ${{ secrets.POSTGRES_CONNECTOR_REFRESH_DATABASE }}
        run: |
          echo "UPDATE connector_tags SET job_status='{\"type\": \"queued\"}'
                  WHERE connector_id IN (
                    SELECT id FROM connectors WHERE image_name='ghcr.io/estuary/${{ matrix.connector }}'
                  )
                  AND
                  image_tag IN (':${{ steps.prep.outputs.version }}', ':dev');" | psql

  build_variants:
    runs-on: ubuntu-20.04
    needs: build_connectors
    strategy:
      fail-fast: false
      matrix:
        variant:
          # Additional image variants, which are built by extending existing "base" dockerfiles and
          # tagged as `tag`. The `docsURL` value is provided to the connector as an environment
          # variable to override the default value. Currently only SQL capture and SQL
          # materialization connectors support being built as variants in this way.
          - tag: source-mariadb
            base: source-mysql
            docsURL: "https://go.estuary.dev/source-mariadb"
          - tag: source-amazon-aurora-mysql
            base: source-mysql
            docsURL: "https://go.estuary.dev/source-amazon-aurora-mysql"
          - tag: source-alloydb
            base: source-postgres
            docsURL: "https://go.estuary.dev/source-alloydb"
          - tag: source-amazon-aurora-postgres
            base: source-postgres
            docsURL: "https://go.estuary.dev/source-amazon-aurora-postgres"
          - tag: source-azure-sqlserver
            base: source-sqlserver
            docsURL: "https://go.estuary.dev/source-azure-sqlserver"
          - tag: materialize-timescaledb
            base: materialize-postgres
            docsURL: "https://go.estuary.dev/materialize-timescaledb"
          - tag: materialize-alloydb
            base: materialize-postgres
            docsURL: "https://go.estuary.dev/materialize-alloydb"
          - tag: materialize-amazon-aurora-postgres
            base: materialize-postgres
            docsURL: "https://go.estuary.dev/materialize-amazon-aurora-postgres"

    steps:
      - uses: actions/checkout@v2
        with:
          fetch-depth: 0

      - name: Prepare
        id: prep
        run: |
          TAG=$(echo $GITHUB_SHA | head -c7)
          echo ::set-output name=tag::${TAG}
          VERSION=$(cat ${{ matrix.variant.base }}/VERSION | tr -d '\n')
          echo ::set-output name=version::${VERSION}

      - name: Login to GitHub package docker registry
        run: |
          echo "${{ secrets.GITHUB_TOKEN }}" | \
            docker login --username ${{ github.actor }} --password-stdin ghcr.io

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v1

      - name: Push ${{ matrix.variant.tag }} image with commit SHA tag
        uses: docker/build-push-action@v2
        with:
          context: .
          build-args: |
            BASE_CONNECTOR=ghcr.io/estuary/${{ matrix.variant.base }}:${{ steps.prep.outputs.tag }}
            DOCS_URL=${{ matrix.variant.docsURL }}
          file: connector-variant.Dockerfile
          push: true
          tags: ghcr.io/estuary/${{ matrix.variant.tag }}:${{ steps.prep.outputs.tag }}

      - name: Push ${{ matrix.variant.tag }} image with 'dev' and $VERSION tag
        if: ${{ github.event_name == 'push' }}
        uses: docker/build-push-action@v2
        with:
          context: .
          build-args: |
            BASE_CONNECTOR=ghcr.io/estuary/${{ matrix.variant.base }}:${{ steps.prep.outputs.tag }}
            DOCS_URL=${{ matrix.variant.docsURL }}
          file: connector-variant.Dockerfile
          push: true # See 'if' above
          tags: ghcr.io/estuary/${{ matrix.variant.tag }}:dev,ghcr.io/estuary/${{ matrix.variant.tag }}:${{ steps.prep.outputs.version }}

      - name: Install psql
        if: ${{ github.event_name == 'push' }}
        run: |
          sudo apt update
          sudo apt install postgresql

      - name: Refresh connector tags for ${{ matrix.variant.tag }}
        if: ${{ github.event_name == 'push' }}
        env:
          PGHOST: ${{ secrets.POSTGRES_CONNECTOR_REFRESH_HOST }}
          PGUSER: ${{ secrets.POSTGRES_CONNECTOR_REFRESH_USER }}
          PGPASSWORD: ${{ secrets.POSTGRES_CONNECTOR_REFRESH_PASSWORD }}
          PGDATABASE: ${{ secrets.POSTGRES_CONNECTOR_REFRESH_DATABASE }}
        run: |
          echo "UPDATE connector_tags SET job_status='{\"type\": \"queued\"}'
                  WHERE connector_id IN (
                    SELECT id FROM connectors WHERE image_name='ghcr.io/estuary/${{ matrix.variant.tag }}'
                  )
                  AND
                  image_tag IN (':${{ steps.prep.outputs.version }}', ':dev');" | psql
